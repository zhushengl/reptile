2018-10-05 15:00:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:00:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:00:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:02:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:02:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:02:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:05:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:05:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:05:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:08:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:08:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:08:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:08:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:08:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:08:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:09:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:09:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:09:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:10:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:10:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:10:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:12:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:12:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-10-05 15:12:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'hungrySpider', 'DOWNLOAD_DELAY': 3, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'hungry.log', 'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'}
2018-10-05 15:56:02 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:56:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 15:57:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 15:57:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:00:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:00:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:00:59 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:00:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:00:59 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:01:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:01:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:01:00 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:01:00 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\python27\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\python27\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\python27\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\python27\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "D:\python27\lib\importlib\__init__.py", line 37, in import_module
    __import__(name)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\pipelines.py", line 9, in <module>
    import xlwt
ImportError: No module named xlwt
2018-10-05 16:01:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:01:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:01:51 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:01:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:01:51 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:01:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:01:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:01:52 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:01:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55066/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:01:54 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55066
2018-10-05 16:02:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55066 "POST /session HTTP/1.1" 200 888
2018-10-05 16:02:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:02:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55066/session/6078efe30314e33b898d696a171a03f1/url {"url": "https://www.ele.me/home/", "sessionId": "6078efe30314e33b898d696a171a03f1"}
2018-10-05 16:02:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55066 "POST /session/6078efe30314e33b898d696a171a03f1/url HTTP/1.1" 200 72
2018-10-05 16:02:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:03:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55066/session/6078efe30314e33b898d696a171a03f1/element {"using": "class name", "sessionId": "6078efe30314e33b898d696a171a03f1", "value": "mapcity-current ng-binding"}
2018-10-05 16:03:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55066 "POST /session/6078efe30314e33b898d696a171a03f1/element HTTP/1.1" 200 299
2018-10-05 16:03:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:03:01 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:05:15 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:05:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:05:15 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:05:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:05:16 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:05:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:05:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:05:17 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:05:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55537/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:05:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55537
2018-10-05 16:05:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55537 "POST /session HTTP/1.1" 200 887
2018-10-05 16:05:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:05:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55537/session/6d7bde0622102061dd443201583cafee/url {"url": "https://www.ele.me/home/", "sessionId": "6d7bde0622102061dd443201583cafee"}
2018-10-05 16:05:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55537 "POST /session/6d7bde0622102061dd443201583cafee/url HTTP/1.1" 200 72
2018-10-05 16:05:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:05:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55537/session/6d7bde0622102061dd443201583cafee/element {"using": "class name", "sessionId": "6d7bde0622102061dd443201583cafee", "value": "mapcity-current ng-binding"}
2018-10-05 16:05:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55537 "POST /session/6d7bde0622102061dd443201583cafee/element HTTP/1.1" 200 299
2018-10-05 16:05:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:05:26 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:05:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 31, in start_requests
    driver.find_element_by_class_name('mapcity-current ng-binding').click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:08:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:08:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:08:31 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:08:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:08:31 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:08:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:08:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:08:32 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:08:33 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55907/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:08:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55907
2018-10-05 16:08:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55907 "POST /session HTTP/1.1" 200 885
2018-10-05 16:08:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:08:37 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55907/session/fc56a1b85ba3ba88d9808310390620b2/url {"url": "https://www.ele.me/home/", "sessionId": "fc56a1b85ba3ba88d9808310390620b2"}
2018-10-05 16:09:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55907 "POST /session/fc56a1b85ba3ba88d9808310390620b2/url HTTP/1.1" 200 72
2018-10-05 16:09:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:09:10 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:55907/session/fc56a1b85ba3ba88d9808310390620b2/screenshot {"sessionId": "fc56a1b85ba3ba88d9808310390620b2"}
2018-10-05 16:09:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55907 "GET /session/fc56a1b85ba3ba88d9808310390620b2/screenshot HTTP/1.1" 200 33886
2018-10-05 16:09:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55907/session/fc56a1b85ba3ba88d9808310390620b2/element {"using": "class name", "sessionId": "fc56a1b85ba3ba88d9808310390620b2", "value": "mapcity-current ng-binding"}
2018-10-05 16:09:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55907 "POST /session/fc56a1b85ba3ba88d9808310390620b2/element HTTP/1.1" 200 299
2018-10-05 16:09:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:09:13 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:09:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 32, in start_requests
    driver.find_element_by_class_name('mapcity-current ng-binding').click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:12:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:12:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:12:09 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:12:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:12:09 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:12:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:12:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:12:10 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:12:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56293/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:12:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:56293
2018-10-05 16:12:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56293 "POST /session HTTP/1.1" 200 886
2018-10-05 16:12:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:12:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56293/session/a5b72ee21094a13245fffb8d0f000b7e/url {"url": "https://www.ele.me/home/", "sessionId": "a5b72ee21094a13245fffb8d0f000b7e"}
2018-10-05 16:12:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56293 "POST /session/a5b72ee21094a13245fffb8d0f000b7e/url HTTP/1.1" 200 72
2018-10-05 16:12:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:12:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:56293/session/a5b72ee21094a13245fffb8d0f000b7e/screenshot {"sessionId": "a5b72ee21094a13245fffb8d0f000b7e"}
2018-10-05 16:12:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56293 "GET /session/a5b72ee21094a13245fffb8d0f000b7e/screenshot HTTP/1.1" 200 33886
2018-10-05 16:12:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:12:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56293/session/a5b72ee21094a13245fffb8d0f000b7e/element {"using": "class name", "sessionId": "a5b72ee21094a13245fffb8d0f000b7e", "value": "mapcity-current ng-binding"}
2018-10-05 16:12:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56293 "POST /session/a5b72ee21094a13245fffb8d0f000b7e/element HTTP/1.1" 200 299
2018-10-05 16:12:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:12:25 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:12:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 32, in start_requests
    driver.find_element_by_class_name('mapcity-current ng-binding').click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:13:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:13:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:13:11 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:13:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:13:11 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:13:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:13:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:13:12 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:13:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56431/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:13:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:56431
2018-10-05 16:13:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56431 "POST /session HTTP/1.1" 200 888
2018-10-05 16:13:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:13:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56431/session/15c5d802006893d96744f4f4e6885f11/url {"url": "https://www.ele.me/home/", "sessionId": "15c5d802006893d96744f4f4e6885f11"}
2018-10-05 16:13:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56431 "POST /session/15c5d802006893d96744f4f4e6885f11/url HTTP/1.1" 200 72
2018-10-05 16:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:56431/session/15c5d802006893d96744f4f4e6885f11/screenshot {"sessionId": "15c5d802006893d96744f4f4e6885f11"}
2018-10-05 16:13:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56431 "GET /session/15c5d802006893d96744f4f4e6885f11/screenshot HTTP/1.1" 200 33886
2018-10-05 16:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56431/session/15c5d802006893d96744f4f4e6885f11/element {"using": "class name", "sessionId": "15c5d802006893d96744f4f4e6885f11", "value": "mapcity-current ng-binding"}
2018-10-05 16:13:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56431 "POST /session/15c5d802006893d96744f4f4e6885f11/element HTTP/1.1" 200 299
2018-10-05 16:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:13:23 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:13:23 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 32, in start_requests
    driver.find_element_by_class_name('mapcity-current ng-binding').click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:14:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:14:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:14:32 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:14:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:14:32 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:14:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:14:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:14:33 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:14:34 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56591/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:14:34 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:56591
2018-10-05 16:14:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56591 "POST /session HTTP/1.1" 200 886
2018-10-05 16:14:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:14:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56591/session/8af812b3c6f73182ad87ef853e70cafb/url {"url": "https://www.ele.me/home/", "sessionId": "8af812b3c6f73182ad87ef853e70cafb"}
2018-10-05 16:14:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56591 "POST /session/8af812b3c6f73182ad87ef853e70cafb/url HTTP/1.1" 200 72
2018-10-05 16:14:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:14:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:56591/session/8af812b3c6f73182ad87ef853e70cafb/screenshot {"sessionId": "8af812b3c6f73182ad87ef853e70cafb"}
2018-10-05 16:14:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56591 "GET /session/8af812b3c6f73182ad87ef853e70cafb/screenshot HTTP/1.1" 200 33886
2018-10-05 16:14:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:14:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56591/session/8af812b3c6f73182ad87ef853e70cafb/element {"using": "class name", "sessionId": "8af812b3c6f73182ad87ef853e70cafb", "value": "mapcity-current ng-binding"}
2018-10-05 16:14:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56591 "POST /session/8af812b3c6f73182ad87ef853e70cafb/element HTTP/1.1" 200 299
2018-10-05 16:14:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:14:46 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:14:46 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 32, in start_requests
    driver.find_element_by_class_name('mapcity-current ng-binding').click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:16:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:16:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:16:10 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:16:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:16:10 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:16:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:16:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:16:11 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:16:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:16:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:56778
2018-10-05 16:16:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session HTTP/1.1" 200 887
2018-10-05 16:16:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/url {"url": "https://www.ele.me/home/", "sessionId": "12df3b1b27a8c4d73740854f34af0a86"}
2018-10-05 16:16:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session/12df3b1b27a8c4d73740854f34af0a86/url HTTP/1.1" 200 72
2018-10-05 16:16:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:41 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/screenshot {"sessionId": "12df3b1b27a8c4d73740854f34af0a86"}
2018-10-05 16:16:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "GET /session/12df3b1b27a8c4d73740854f34af0a86/screenshot HTTP/1.1" 200 33886
2018-10-05 16:16:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/element {"using": "xpath", "sessionId": "12df3b1b27a8c4d73740854f34af0a86", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:16:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session/12df3b1b27a8c4d73740854f34af0a86/element HTTP/1.1" 200 102
2018-10-05 16:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/element/0.5017465985376803-1/click {"sessionId": "12df3b1b27a8c4d73740854f34af0a86", "id": "0.5017465985376803-1"}
2018-10-05 16:16:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session/12df3b1b27a8c4d73740854f34af0a86/element/0.5017465985376803-1/click HTTP/1.1" 200 72
2018-10-05 16:16:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/url {"url": "https://www.ele.me/home/", "sessionId": "12df3b1b27a8c4d73740854f34af0a86"}
2018-10-05 16:16:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session/12df3b1b27a8c4d73740854f34af0a86/url HTTP/1.1" 200 72
2018-10-05 16:16:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56778/session/12df3b1b27a8c4d73740854f34af0a86/element {"using": "name", "sessionId": "12df3b1b27a8c4d73740854f34af0a86", "value": "name"}
2018-10-05 16:16:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56778 "POST /session/12df3b1b27a8c4d73740854f34af0a86/element HTTP/1.1" 200 332
2018-10-05 16:16:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:16:54 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:16:54 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 39, in start_requests
    driver.find_element_by_name('name').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 496, in find_element_by_name
    return self.find_element(by=By.NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"name","selector":"name"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:20:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:20:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:20:43 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:20:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:20:43 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:20:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:20:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:20:44 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:20:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:20:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57229
2018-10-05 16:20:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session HTTP/1.1" 200 887
2018-10-05 16:20:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:20:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session/622d1aa63a51ffe3b55f0dbe2f57c0f1/url {"url": "https://www.ele.me/home/", "sessionId": "622d1aa63a51ffe3b55f0dbe2f57c0f1"}
2018-10-05 16:20:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session/622d1aa63a51ffe3b55f0dbe2f57c0f1/url HTTP/1.1" 200 72
2018-10-05 16:20:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:20:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element {"using": "xpath", "sessionId": "622d1aa63a51ffe3b55f0dbe2f57c0f1", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:20:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element HTTP/1.1" 200 103
2018-10-05 16:20:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:20:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element/0.05784334757680876-1/click {"sessionId": "622d1aa63a51ffe3b55f0dbe2f57c0f1", "id": "0.05784334757680876-1"}
2018-10-05 16:20:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element/0.05784334757680876-1/click HTTP/1.1" 200 72
2018-10-05 16:20:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:21:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session/622d1aa63a51ffe3b55f0dbe2f57c0f1/url {"url": "https://www.ele.me/home/", "sessionId": "622d1aa63a51ffe3b55f0dbe2f57c0f1"}
2018-10-05 16:21:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session/622d1aa63a51ffe3b55f0dbe2f57c0f1/url HTTP/1.1" 200 72
2018-10-05 16:21:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:21:04 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57229/session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element {"using": "xpath", "sessionId": "622d1aa63a51ffe3b55f0dbe2f57c0f1", "value": "//input[@name='name']"}
2018-10-05 16:21:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57229 "POST /session/622d1aa63a51ffe3b55f0dbe2f57c0f1/element HTTP/1.1" 200 350
2018-10-05 16:21:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:21:04 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:21:04 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 40, in start_requests
    driver.find_element_by_xpath("//input[@name='name']").send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@name='name']"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:22:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:22:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:22:51 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:22:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:22:51 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:22:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:22:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:22:51 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:22:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57463/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:22:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57463
2018-10-05 16:22:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57463 "POST /session HTTP/1.1" 200 886
2018-10-05 16:22:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:22:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57463/session/4e2ac7737257f7eeaa81c2e80d45a1ba/url {"url": "https://www.ele.me/home/", "sessionId": "4e2ac7737257f7eeaa81c2e80d45a1ba"}
2018-10-05 16:23:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57463 "POST /session/4e2ac7737257f7eeaa81c2e80d45a1ba/url HTTP/1.1" 200 72
2018-10-05 16:23:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57463/session/4e2ac7737257f7eeaa81c2e80d45a1ba/element {"using": "xpath", "sessionId": "4e2ac7737257f7eeaa81c2e80d45a1ba", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:23:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57463 "POST /session/4e2ac7737257f7eeaa81c2e80d45a1ba/element HTTP/1.1" 200 102
2018-10-05 16:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:23:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57463/session/4e2ac7737257f7eeaa81c2e80d45a1ba/element/0.5987867161292237-1/click {"sessionId": "4e2ac7737257f7eeaa81c2e80d45a1ba", "id": "0.5987867161292237-1"}
2018-10-05 16:23:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57463 "POST /session/4e2ac7737257f7eeaa81c2e80d45a1ba/element/0.5987867161292237-1/click HTTP/1.1" 200 72
2018-10-05 16:23:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:23:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57463/session/4e2ac7737257f7eeaa81c2e80d45a1ba/element {"using": "xpath", "sessionId": "4e2ac7737257f7eeaa81c2e80d45a1ba", "value": "//input[@name='name']"}
2018-10-05 16:23:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57463 "POST /session/4e2ac7737257f7eeaa81c2e80d45a1ba/element HTTP/1.1" 200 102
2018-10-05 16:23:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:23:10 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:23:10 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath("//input[@name='name']").send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 479, in send_keys
    'value': keys_to_typing(value)})
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    data = utils.dump_json(params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\utils.py", line 33, in dump_json
    return json.dumps(json_struct)
  File "D:\python27\lib\json\__init__.py", line 244, in dumps
    return _default_encoder.encode(obj)
  File "D:\python27\lib\json\encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "D:\python27\lib\json\encoder.py", line 270, in iterencode
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 0: unexpected end of data
2018-10-05 16:24:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:24:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:24:50 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:24:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:24:50 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:24:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:24:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:24:51 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:24:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57688/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:24:51 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57688
2018-10-05 16:24:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57688 "POST /session HTTP/1.1" 200 887
2018-10-05 16:24:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:24:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57688/session/92b1052697fc5f733b0c828ed9a57d47/url {"url": "https://www.ele.me/home/", "sessionId": "92b1052697fc5f733b0c828ed9a57d47"}
2018-10-05 16:24:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57688 "POST /session/92b1052697fc5f733b0c828ed9a57d47/url HTTP/1.1" 200 72
2018-10-05 16:24:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:24:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57688/session/92b1052697fc5f733b0c828ed9a57d47/element {"using": "xpath", "sessionId": "92b1052697fc5f733b0c828ed9a57d47", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:24:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57688 "POST /session/92b1052697fc5f733b0c828ed9a57d47/element HTTP/1.1" 200 102
2018-10-05 16:24:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:24:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57688/session/92b1052697fc5f733b0c828ed9a57d47/element/0.7009498043592419-1/click {"sessionId": "92b1052697fc5f733b0c828ed9a57d47", "id": "0.7009498043592419-1"}
2018-10-05 16:25:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57688 "POST /session/92b1052697fc5f733b0c828ed9a57d47/element/0.7009498043592419-1/click HTTP/1.1" 200 72
2018-10-05 16:25:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57688/session/92b1052697fc5f733b0c828ed9a57d47/element {"using": "xpath", "sessionId": "92b1052697fc5f733b0c828ed9a57d47", "value": "//input[@name='name']"}
2018-10-05 16:25:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57688 "POST /session/92b1052697fc5f733b0c828ed9a57d47/element HTTP/1.1" 200 102
2018-10-05 16:25:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:02 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:25:02 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath("//input[@name='name']").send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 479, in send_keys
    'value': keys_to_typing(value)})
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    data = utils.dump_json(params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\utils.py", line 33, in dump_json
    return json.dumps(json_struct)
  File "D:\python27\lib\json\__init__.py", line 244, in dumps
    return _default_encoder.encode(obj)
  File "D:\python27\lib\json\encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "D:\python27\lib\json\encoder.py", line 270, in iterencode
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 0: unexpected end of data
2018-10-05 16:25:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:25:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:25:17 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:25:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:25:17 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:25:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:25:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:25:18 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:25:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57767/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:25:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57767
2018-10-05 16:25:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57767 "POST /session HTTP/1.1" 200 887
2018-10-05 16:25:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57767/session/878ab679ff8713c6e288da87c56ccde3/url {"url": "https://www.ele.me/home/", "sessionId": "878ab679ff8713c6e288da87c56ccde3"}
2018-10-05 16:25:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57767 "POST /session/878ab679ff8713c6e288da87c56ccde3/url HTTP/1.1" 200 72
2018-10-05 16:25:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57767/session/878ab679ff8713c6e288da87c56ccde3/element {"using": "xpath", "sessionId": "878ab679ff8713c6e288da87c56ccde3", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:25:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57767 "POST /session/878ab679ff8713c6e288da87c56ccde3/element HTTP/1.1" 200 103
2018-10-05 16:25:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57767/session/878ab679ff8713c6e288da87c56ccde3/element/0.23768281474836872-1/click {"sessionId": "878ab679ff8713c6e288da87c56ccde3", "id": "0.23768281474836872-1"}
2018-10-05 16:25:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57767 "POST /session/878ab679ff8713c6e288da87c56ccde3/element/0.23768281474836872-1/click HTTP/1.1" 200 72
2018-10-05 16:25:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57767/session/878ab679ff8713c6e288da87c56ccde3/element {"using": "xpath", "sessionId": "878ab679ff8713c6e288da87c56ccde3", "value": "//input[@name='name']"}
2018-10-05 16:25:31 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57767 "POST /session/878ab679ff8713c6e288da87c56ccde3/element HTTP/1.1" 200 103
2018-10-05 16:25:31 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:25:31 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:25:31 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath("//input[@name='name']").send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 479, in send_keys
    'value': keys_to_typing(value)})
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webelement.py", line 633, in _execute
    return self._parent.execute(command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 374, in execute
    data = utils.dump_json(params)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\utils.py", line 33, in dump_json
    return json.dumps(json_struct)
  File "D:\python27\lib\json\__init__.py", line 244, in dumps
    return _default_encoder.encode(obj)
  File "D:\python27\lib\json\encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "D:\python27\lib\json\encoder.py", line 270, in iterencode
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xe4 in position 0: unexpected end of data
2018-10-05 16:27:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:27:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:27:43 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:27:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:27:43 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:27:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:27:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:27:44 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:27:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58019/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:27:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58019
2018-10-05 16:27:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58019 "POST /session HTTP/1.1" 200 888
2018-10-05 16:27:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:27:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58019/session/14ff7c223d3d77c595c2fec3851d3a47/url {"url": "https://www.ele.me/home/", "sessionId": "14ff7c223d3d77c595c2fec3851d3a47"}
2018-10-05 16:27:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58019 "POST /session/14ff7c223d3d77c595c2fec3851d3a47/url HTTP/1.1" 200 72
2018-10-05 16:27:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:27:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58019/session/14ff7c223d3d77c595c2fec3851d3a47/element {"using": "xpath", "sessionId": "14ff7c223d3d77c595c2fec3851d3a47", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:27:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58019 "POST /session/14ff7c223d3d77c595c2fec3851d3a47/element HTTP/1.1" 200 103
2018-10-05 16:27:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:27:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58019/session/14ff7c223d3d77c595c2fec3851d3a47/element/0.40931445358692353-1/click {"sessionId": "14ff7c223d3d77c595c2fec3851d3a47", "id": "0.40931445358692353-1"}
2018-10-05 16:27:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58019 "POST /session/14ff7c223d3d77c595c2fec3851d3a47/element/0.40931445358692353-1/click HTTP/1.1" 200 72
2018-10-05 16:27:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:27:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58019/session/14ff7c223d3d77c595c2fec3851d3a47/element {"using": "xpath", "sessionId": "14ff7c223d3d77c595c2fec3851d3a47", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:27:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58019 "POST /session/14ff7c223d3d77c595c2fec3851d3a47/element HTTP/1.1" 200 366
2018-10-05 16:27:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:27:58 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:27:58 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:30:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:30:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:30:04 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:30:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:30:04 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:30:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:30:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:30:05 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:30:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58264/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:30:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58264
2018-10-05 16:30:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58264 "POST /session HTTP/1.1" 200 887
2018-10-05 16:30:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:30:08 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58264/session/85981aa6b77a89448087272a24506588/url {"url": "https://www.ele.me/home/", "sessionId": "85981aa6b77a89448087272a24506588"}
2018-10-05 16:30:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58264 "POST /session/85981aa6b77a89448087272a24506588/url HTTP/1.1" 200 72
2018-10-05 16:30:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:30:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58264/session/85981aa6b77a89448087272a24506588/element {"using": "xpath", "sessionId": "85981aa6b77a89448087272a24506588", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:30:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58264 "POST /session/85981aa6b77a89448087272a24506588/element HTTP/1.1" 200 102
2018-10-05 16:30:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:30:27 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58264/session/85981aa6b77a89448087272a24506588/element/0.6663430012351295-1/click {"sessionId": "85981aa6b77a89448087272a24506588", "id": "0.6663430012351295-1"}
2018-10-05 16:30:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58264 "POST /session/85981aa6b77a89448087272a24506588/element/0.6663430012351295-1/click HTTP/1.1" 200 72
2018-10-05 16:30:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:30:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58264/session/85981aa6b77a89448087272a24506588/element {"using": "xpath", "sessionId": "85981aa6b77a89448087272a24506588", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:30:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58264 "POST /session/85981aa6b77a89448087272a24506588/element HTTP/1.1" 200 366
2018-10-05 16:30:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:30:30 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:30:30 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:31:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:31:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:31:50 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:31:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:31:50 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:31:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:31:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:31:51 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:31:52 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58469/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:31:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58469
2018-10-05 16:31:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58469 "POST /session HTTP/1.1" 200 887
2018-10-05 16:31:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:31:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58469/session/c7eb573ed3f9c59370b4b97fcd956541/url {"url": "https://www.ele.me/home/", "sessionId": "c7eb573ed3f9c59370b4b97fcd956541"}
2018-10-05 16:32:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58469 "POST /session/c7eb573ed3f9c59370b4b97fcd956541/url HTTP/1.1" 200 72
2018-10-05 16:32:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58469/session/c7eb573ed3f9c59370b4b97fcd956541/element {"using": "xpath", "sessionId": "c7eb573ed3f9c59370b4b97fcd956541", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:32:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58469 "POST /session/c7eb573ed3f9c59370b4b97fcd956541/element HTTP/1.1" 200 103
2018-10-05 16:32:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58469/session/c7eb573ed3f9c59370b4b97fcd956541/element/0.15172388456689956-1/click {"sessionId": "c7eb573ed3f9c59370b4b97fcd956541", "id": "0.15172388456689956-1"}
2018-10-05 16:32:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58469 "POST /session/c7eb573ed3f9c59370b4b97fcd956541/element/0.15172388456689956-1/click HTTP/1.1" 200 72
2018-10-05 16:32:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58469/session/c7eb573ed3f9c59370b4b97fcd956541/element {"using": "xpath", "sessionId": "c7eb573ed3f9c59370b4b97fcd956541", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:32:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58469 "POST /session/c7eb573ed3f9c59370b4b97fcd956541/element HTTP/1.1" 200 366
2018-10-05 16:32:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:14 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:32:14 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:32:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:32:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:32:33 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:32:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:32:33 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:32:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:32:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:32:34 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:32:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58578/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:32:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58578
2018-10-05 16:32:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58578 "POST /session HTTP/1.1" 200 888
2018-10-05 16:32:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:38 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58578/session/8a3e64ba4300124fe504cd8fed3dca1d/url {"url": "https://www.ele.me/home/", "sessionId": "8a3e64ba4300124fe504cd8fed3dca1d"}
2018-10-05 16:32:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58578 "POST /session/8a3e64ba4300124fe504cd8fed3dca1d/url HTTP/1.1" 200 72
2018-10-05 16:32:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58578/session/8a3e64ba4300124fe504cd8fed3dca1d/element {"using": "xpath", "sessionId": "8a3e64ba4300124fe504cd8fed3dca1d", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:32:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58578 "POST /session/8a3e64ba4300124fe504cd8fed3dca1d/element HTTP/1.1" 200 102
2018-10-05 16:32:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58578/session/8a3e64ba4300124fe504cd8fed3dca1d/element/0.8812626185229897-1/click {"sessionId": "8a3e64ba4300124fe504cd8fed3dca1d", "id": "0.8812626185229897-1"}
2018-10-05 16:32:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58578 "POST /session/8a3e64ba4300124fe504cd8fed3dca1d/element/0.8812626185229897-1/click HTTP/1.1" 200 72
2018-10-05 16:32:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58578/session/8a3e64ba4300124fe504cd8fed3dca1d/element {"using": "xpath", "sessionId": "8a3e64ba4300124fe504cd8fed3dca1d", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:32:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58578 "POST /session/8a3e64ba4300124fe504cd8fed3dca1d/element HTTP/1.1" 200 366
2018-10-05 16:32:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:32:46 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:32:46 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:32:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:32:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:32:58 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:32:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:32:58 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:32:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:32:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:32:59 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:33:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58654/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:33:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58654
2018-10-05 16:33:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58654 "POST /session HTTP/1.1" 200 886
2018-10-05 16:33:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:33:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58654/session/f531fe0cd8ae1eccc43936af93606316/url {"url": "https://www.ele.me/home/", "sessionId": "f531fe0cd8ae1eccc43936af93606316"}
2018-10-05 16:33:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58654 "POST /session/f531fe0cd8ae1eccc43936af93606316/url HTTP/1.1" 200 72
2018-10-05 16:33:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:33:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58654/session/f531fe0cd8ae1eccc43936af93606316/element {"using": "xpath", "sessionId": "f531fe0cd8ae1eccc43936af93606316", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-05 16:33:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58654 "POST /session/f531fe0cd8ae1eccc43936af93606316/element HTTP/1.1" 200 102
2018-10-05 16:33:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:33:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58654/session/f531fe0cd8ae1eccc43936af93606316/element/0.1816845121535513-1/click {"sessionId": "f531fe0cd8ae1eccc43936af93606316", "id": "0.1816845121535513-1"}
2018-10-05 16:33:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58654 "POST /session/f531fe0cd8ae1eccc43936af93606316/element/0.1816845121535513-1/click HTTP/1.1" 200 72
2018-10-05 16:33:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:33:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58654/session/f531fe0cd8ae1eccc43936af93606316/element {"using": "xpath", "sessionId": "f531fe0cd8ae1eccc43936af93606316", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:33:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58654 "POST /session/f531fe0cd8ae1eccc43936af93606316/element HTTP/1.1" 200 366
2018-10-05 16:33:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:33:18 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:33:18 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 37, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(city_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:34:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:34:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:34:51 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:34:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:34:52 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:34:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:34:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:34:52 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:34:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58869/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:34:53 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58869
2018-10-05 16:34:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58869 "POST /session HTTP/1.1" 200 886
2018-10-05 16:34:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:34:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58869/session/91e112c8882a516717ca6a65636e0875/url {"url": "https://www.ele.me/home/", "sessionId": "91e112c8882a516717ca6a65636e0875"}
2018-10-05 16:35:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58869 "POST /session/91e112c8882a516717ca6a65636e0875/url HTTP/1.1" 200 72
2018-10-05 16:35:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58869/session/91e112c8882a516717ca6a65636e0875/url {"url": "https://www.ele.me/home/", "sessionId": "91e112c8882a516717ca6a65636e0875"}
2018-10-05 16:35:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58869 "POST /session/91e112c8882a516717ca6a65636e0875/url HTTP/1.1" 200 72
2018-10-05 16:35:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58869/session/91e112c8882a516717ca6a65636e0875/element {"using": "xpath", "sessionId": "91e112c8882a516717ca6a65636e0875", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:35:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58869 "POST /session/91e112c8882a516717ca6a65636e0875/element HTTP/1.1" 200 366
2018-10-05 16:35:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:10 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:35:10 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(local_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:35:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:35:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:35:20 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:35:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:35:20 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:35:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:35:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:35:21 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:35:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58965/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:35:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58965
2018-10-05 16:35:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58965 "POST /session HTTP/1.1" 200 886
2018-10-05 16:35:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58965/session/31ea4c30b643a02e3d752d3659ef1b14/url {"url": "https://www.ele.me/home/", "sessionId": "31ea4c30b643a02e3d752d3659ef1b14"}
2018-10-05 16:35:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58965 "POST /session/31ea4c30b643a02e3d752d3659ef1b14/url HTTP/1.1" 200 72
2018-10-05 16:35:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58965/session/31ea4c30b643a02e3d752d3659ef1b14/url {"url": "https://www.ele.me/home/", "sessionId": "31ea4c30b643a02e3d752d3659ef1b14"}
2018-10-05 16:35:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58965 "POST /session/31ea4c30b643a02e3d752d3659ef1b14/url HTTP/1.1" 200 72
2018-10-05 16:35:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58965/session/31ea4c30b643a02e3d752d3659ef1b14/element {"using": "xpath", "sessionId": "31ea4c30b643a02e3d752d3659ef1b14", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:35:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58965 "POST /session/31ea4c30b643a02e3d752d3659ef1b14/element HTTP/1.1" 200 366
2018-10-05 16:35:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:35:33 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:35:33 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(local_address)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:36:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:36:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:36:23 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:36:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:36:23 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:36:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:36:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:36:24 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:36:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59099/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:36:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:59099
2018-10-05 16:36:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59099 "POST /session HTTP/1.1" 200 887
2018-10-05 16:36:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:36:29 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59099/session/7f9ae8b02230c0303192e188a852106c/url {"url": "https://www.ele.me/home/", "sessionId": "7f9ae8b02230c0303192e188a852106c"}
2018-10-05 16:36:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59099 "POST /session/7f9ae8b02230c0303192e188a852106c/url HTTP/1.1" 200 72
2018-10-05 16:36:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:36:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59099/session/7f9ae8b02230c0303192e188a852106c/url {"url": "https://www.ele.me/home/", "sessionId": "7f9ae8b02230c0303192e188a852106c"}
2018-10-05 16:36:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59099 "POST /session/7f9ae8b02230c0303192e188a852106c/url HTTP/1.1" 200 72
2018-10-05 16:36:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59099/session/7f9ae8b02230c0303192e188a852106c/element {"using": "xpath", "sessionId": "7f9ae8b02230c0303192e188a852106c", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:36:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59099 "POST /session/7f9ae8b02230c0303192e188a852106c/element HTTP/1.1" 200 366
2018-10-05 16:36:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:36:43 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:36:43 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys(r"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:38:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:38:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:38:40 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:38:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:38:40 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:38:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:38:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:38:41 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:38:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59454/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:38:41 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:59454
2018-10-05 16:38:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59454 "POST /session HTTP/1.1" 200 888
2018-10-05 16:38:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:38:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59454/session/c30ec33b2dbd2066fc3f515d55ab09a6/url {"url": "https://www.ele.me/home/", "sessionId": "c30ec33b2dbd2066fc3f515d55ab09a6"}
2018-10-05 16:38:53 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59454 "POST /session/c30ec33b2dbd2066fc3f515d55ab09a6/url HTTP/1.1" 200 72
2018-10-05 16:38:53 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:38:53 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59454/session/c30ec33b2dbd2066fc3f515d55ab09a6/url {"url": "https://www.ele.me/home/", "sessionId": "c30ec33b2dbd2066fc3f515d55ab09a6"}
2018-10-05 16:38:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59454 "POST /session/c30ec33b2dbd2066fc3f515d55ab09a6/url HTTP/1.1" 200 72
2018-10-05 16:38:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:38:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59454/session/c30ec33b2dbd2066fc3f515d55ab09a6/element {"using": "xpath", "sessionId": "c30ec33b2dbd2066fc3f515d55ab09a6", "value": "//input[@class=\"ng-valid ng-dirty\"]"}
2018-10-05 16:38:58 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59454 "POST /session/c30ec33b2dbd2066fc3f515d55ab09a6/element HTTP/1.1" 200 366
2018-10-05 16:38:58 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:38:58 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:38:58 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_xpath('//input[@class="ng-valid ng-dirty"]').send_keys("国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 394, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchElementException: Message: no such element: Unable to locate element: {"method":"xpath","selector":"//input[@class="ng-valid ng-dirty"]"}
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:40:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:40:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:40:22 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:40:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:40:22 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:40:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:40:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:40:22 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:40:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59656/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:40:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:59656
2018-10-05 16:40:26 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59656 "POST /session HTTP/1.1" 200 888
2018-10-05 16:40:26 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:40:26 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59656/session/cad12da7cbb3dbafe55c0547867f898a/url {"url": "https://www.ele.me/home/", "sessionId": "cad12da7cbb3dbafe55c0547867f898a"}
2018-10-05 16:40:32 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59656 "POST /session/cad12da7cbb3dbafe55c0547867f898a/url HTTP/1.1" 200 72
2018-10-05 16:40:32 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:40:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59656/session/cad12da7cbb3dbafe55c0547867f898a/url {"url": "https://www.ele.me/home/", "sessionId": "cad12da7cbb3dbafe55c0547867f898a"}
2018-10-05 16:40:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59656 "POST /session/cad12da7cbb3dbafe55c0547867f898a/url HTTP/1.1" 200 72
2018-10-05 16:40:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:40:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:59656/session/cad12da7cbb3dbafe55c0547867f898a/element {"using": "class name", "sessionId": "cad12da7cbb3dbafe55c0547867f898a", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 16:40:37 [urllib3.connectionpool] DEBUG: http://127.0.0.1:59656 "POST /session/cad12da7cbb3dbafe55c0547867f898a/element HTTP/1.1" 200 299
2018-10-05 16:40:37 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:40:37 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:40:37 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys("国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:45:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:45:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:45:43 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:45:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:45:43 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:45:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:45:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:45:44 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:45:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60331/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:45:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:60331
2018-10-05 16:45:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60331 "POST /session HTTP/1.1" 200 888
2018-10-05 16:45:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:45:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60331/session/ead24263b01bb40f48b4b82ba0154ca2/url {"url": "https://www.ele.me/home/", "sessionId": "ead24263b01bb40f48b4b82ba0154ca2"}
2018-10-05 16:45:56 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60331 "POST /session/ead24263b01bb40f48b4b82ba0154ca2/url HTTP/1.1" 200 72
2018-10-05 16:45:56 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:45:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60331/session/ead24263b01bb40f48b4b82ba0154ca2/url {"url": "https://www.ele.me/home/", "sessionId": "ead24263b01bb40f48b4b82ba0154ca2"}
2018-10-05 16:45:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60331 "POST /session/ead24263b01bb40f48b4b82ba0154ca2/url HTTP/1.1" 200 72
2018-10-05 16:45:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60331/session/ead24263b01bb40f48b4b82ba0154ca2/element {"using": "class name", "sessionId": "ead24263b01bb40f48b4b82ba0154ca2", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 16:46:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60331 "POST /session/ead24263b01bb40f48b4b82ba0154ca2/element HTTP/1.1" 200 299
2018-10-05 16:46:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:00 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:46:00 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 16:46:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 16:46:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 16:46:20 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 16:46:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 16:46:20 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 16:46:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 16:46:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 16:46:21 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 16:46:22 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60440/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 16:46:22 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:60440
2018-10-05 16:46:25 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60440 "POST /session HTTP/1.1" 200 887
2018-10-05 16:46:25 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:25 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60440/session/de412358cda3a0f8ae4ad71f1f42972e/url {"url": "https://www.ele.me/home/", "sessionId": "de412358cda3a0f8ae4ad71f1f42972e"}
2018-10-05 16:46:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60440 "POST /session/de412358cda3a0f8ae4ad71f1f42972e/url HTTP/1.1" 200 72
2018-10-05 16:46:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60440/session/de412358cda3a0f8ae4ad71f1f42972e/url {"url": "https://www.ele.me/home/", "sessionId": "de412358cda3a0f8ae4ad71f1f42972e"}
2018-10-05 16:46:33 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60440 "POST /session/de412358cda3a0f8ae4ad71f1f42972e/url HTTP/1.1" 200 72
2018-10-05 16:46:33 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:60440/session/de412358cda3a0f8ae4ad71f1f42972e/element {"using": "class name", "sessionId": "de412358cda3a0f8ae4ad71f1f42972e", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 16:46:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:60440 "POST /session/de412358cda3a0f8ae4ad71f1f42972e/element HTTP/1.1" 200 299
2018-10-05 16:46:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 16:46:36 [twisted] CRITICAL: Unhandled error in Deferred:
2018-10-05 16:46:36 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 98, in crawl
    six.reraise(*exc_info)
  File "D:\python27\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 47, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:01:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:01:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:01:13 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:01:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:01:13 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:01:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:01:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:01:14 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:01:14 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:01:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:01:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:01:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:61868/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:01:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:61868
2018-10-05 17:01:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:61868 "POST /session HTTP/1.1" 200 886
2018-10-05 17:01:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:01:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:61868/session/ee7feb36d305fafaa6b68f324c0818a5/url {"url": "https://www.ele.me/home/", "sessionId": "ee7feb36d305fafaa6b68f324c0818a5"}
2018-10-05 17:01:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:61868 "POST /session/ee7feb36d305fafaa6b68f324c0818a5/url HTTP/1.1" 200 72
2018-10-05 17:01:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:01:30 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:61868/session/ee7feb36d305fafaa6b68f324c0818a5/element {"using": "class name", "sessionId": "ee7feb36d305fafaa6b68f324c0818a5", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:01:30 [urllib3.connectionpool] DEBUG: http://127.0.0.1:61868 "POST /session/ee7feb36d305fafaa6b68f324c0818a5/element HTTP/1.1" 200 299
2018-10-05 17:01:30 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:01:30 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:02:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:02:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:02:11 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:02:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:02:11 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:02:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:02:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:02:12 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:02:12 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:02:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:02:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:02:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:02:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:02:18 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:02:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:02:18 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:02:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:02:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:02:19 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:02:19 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:02:19 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:02:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62020/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:02:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62020
2018-10-05 17:02:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62020 "POST /session HTTP/1.1" 200 886
2018-10-05 17:02:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:02:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62020/session/56104c9b2936a69e221c7b8689f848f7/url {"url": "https://www.ele.me/home/", "sessionId": "56104c9b2936a69e221c7b8689f848f7"}
2018-10-05 17:02:36 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62020 "POST /session/56104c9b2936a69e221c7b8689f848f7/url HTTP/1.1" 200 72
2018-10-05 17:02:36 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:02:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62020/session/56104c9b2936a69e221c7b8689f848f7/element {"using": "class name", "sessionId": "56104c9b2936a69e221c7b8689f848f7", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:02:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62020 "POST /session/56104c9b2936a69e221c7b8689f848f7/element HTTP/1.1" 200 299
2018-10-05 17:02:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:02:39 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:03:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:03:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:03:31 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:03:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:03:31 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:03:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:03:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:03:32 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:03:32 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:03:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:03:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:03:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62179/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:03:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62179
2018-10-05 17:03:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62179 "POST /session HTTP/1.1" 200 886
2018-10-05 17:03:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:03:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62179/session/368e8469a29c79f2383cb4b0cb8e85ef/url {"url": "https://www.ele.me/home/", "sessionId": "368e8469a29c79f2383cb4b0cb8e85ef"}
2018-10-05 17:03:52 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62179 "POST /session/368e8469a29c79f2383cb4b0cb8e85ef/url HTTP/1.1" 200 72
2018-10-05 17:03:52 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:03:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62179/session/368e8469a29c79f2383cb4b0cb8e85ef/element {"using": "class name", "sessionId": "368e8469a29c79f2383cb4b0cb8e85ef", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:03:55 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62179 "POST /session/368e8469a29c79f2383cb4b0cb8e85ef/element HTTP/1.1" 200 299
2018-10-05 17:03:55 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:03:55 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 46, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").click()
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:04:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:04:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:04:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:04:56 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:04:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:04:56 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:04:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:04:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:04:57 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:04:57 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:04:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:04:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:04:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62354/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:04:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62354
2018-10-05 17:05:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:05:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:05:04 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:05:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:05:04 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:05:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:05:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:05:05 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:05:05 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:05:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:05:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:05:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62376/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:05:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62376
2018-10-05 17:05:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62376 "POST /session HTTP/1.1" 200 887
2018-10-05 17:05:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:05:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62376/session/4d2b5cedbc7ba34d4c487f2ece03403f/url {"url": "https://www.ele.me/home/", "sessionId": "4d2b5cedbc7ba34d4c487f2ece03403f"}
2018-10-05 17:05:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62376 "POST /session/4d2b5cedbc7ba34d4c487f2ece03403f/url HTTP/1.1" 200 72
2018-10-05 17:05:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:05:19 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62376/session/4d2b5cedbc7ba34d4c487f2ece03403f/element {"using": "class name", "sessionId": "4d2b5cedbc7ba34d4c487f2ece03403f", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:05:19 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62376 "POST /session/4d2b5cedbc7ba34d4c487f2ece03403f/element HTTP/1.1" 200 299
2018-10-05 17:05:19 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:05:19 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 47, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:05:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:05:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:05:56 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:05:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:05:56 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:05:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:05:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:05:57 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:05:57 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:05:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:05:57 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:05:58 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62501/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:05:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62501
2018-10-05 17:06:01 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62501 "POST /session HTTP/1.1" 200 888
2018-10-05 17:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62501/session/fc49599f4fc675934ff13f2219fcfb9d/url {"url": "https://www.ele.me/home/", "sessionId": "fc49599f4fc675934ff13f2219fcfb9d"}
2018-10-05 17:06:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62501 "POST /session/fc49599f4fc675934ff13f2219fcfb9d/url HTTP/1.1" 200 72
2018-10-05 17:06:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:07 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62501/session/fc49599f4fc675934ff13f2219fcfb9d/element {"using": "class name", "sessionId": "fc49599f4fc675934ff13f2219fcfb9d", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:06:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62501 "POST /session/fc49599f4fc675934ff13f2219fcfb9d/element HTTP/1.1" 200 299
2018-10-05 17:06:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:07 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 48, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:06:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:06:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:06:38 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:06:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:06:38 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:06:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:06:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:06:39 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:06:39 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:06:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:06:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:06:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62604/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:06:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62604
2018-10-05 17:06:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62604 "POST /session HTTP/1.1" 200 887
2018-10-05 17:06:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62604/session/75e0b212b75cfab04d79f89cff95339e/url {"url": "https://www.ele.me/home/", "sessionId": "75e0b212b75cfab04d79f89cff95339e"}
2018-10-05 17:06:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62604 "POST /session/75e0b212b75cfab04d79f89cff95339e/url HTTP/1.1" 200 72
2018-10-05 17:06:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:62604/session/75e0b212b75cfab04d79f89cff95339e/url {"sessionId": "75e0b212b75cfab04d79f89cff95339e"}
2018-10-05 17:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62604 "GET /session/75e0b212b75cfab04d79f89cff95339e/url HTTP/1.1" 200 94
2018-10-05 17:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62604/session/75e0b212b75cfab04d79f89cff95339e/element {"using": "class name", "sessionId": "75e0b212b75cfab04d79f89cff95339e", "value": "ng-valid ng-dirty xh-highlight"}
2018-10-05 17:06:57 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62604 "POST /session/75e0b212b75cfab04d79f89cff95339e/element HTTP/1.1" 200 299
2018-10-05 17:06:57 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:06:57 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 49, in start_requests
    driver.find_element_by_class_name("ng-valid ng-dirty xh-highlight").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:07:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:08:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:08:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:08:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:08:58 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:08:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:08:58 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:08:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:08:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:08:59 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:08:59 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:08:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:08:59 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:09:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62872/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:09:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:62872
2018-10-05 17:09:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62872 "POST /session HTTP/1.1" 200 887
2018-10-05 17:09:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:09:03 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62872/session/de16906fec492fbb5df905478c46e8ce/url {"url": "https://www.ele.me/home/", "sessionId": "de16906fec492fbb5df905478c46e8ce"}
2018-10-05 17:09:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62872 "POST /session/de16906fec492fbb5df905478c46e8ce/url HTTP/1.1" 200 72
2018-10-05 17:09:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:62872/session/de16906fec492fbb5df905478c46e8ce/url {"sessionId": "de16906fec492fbb5df905478c46e8ce"}
2018-10-05 17:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62872 "GET /session/de16906fec492fbb5df905478c46e8ce/url HTTP/1.1" 200 94
2018-10-05 17:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:62872/session/de16906fec492fbb5df905478c46e8ce/element {"using": "class name", "sessionId": "de16906fec492fbb5df905478c46e8ce", "value": "ng-pristine ng-valid"}
2018-10-05 17:09:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:62872 "POST /session/de16906fec492fbb5df905478c46e8ce/element HTTP/1.1" 200 299
2018-10-05 17:09:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:09:20 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 49, in start_requests
    driver.find_element_by_class_name("ng-pristine ng-valid").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:09:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:10:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:11:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:13:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:13:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:13:00 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:13:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:13:00 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:13:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:13:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:13:01 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:13:01 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:13:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:13:01 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:13:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63280/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:13:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63280
2018-10-05 17:13:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63280 "POST /session HTTP/1.1" 200 887
2018-10-05 17:13:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:13:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63280/session/04c548dba08b734e0ee32f73f78958a5/url {"url": "https://www.ele.me/home/", "sessionId": "04c548dba08b734e0ee32f73f78958a5"}
2018-10-05 17:13:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63280 "POST /session/04c548dba08b734e0ee32f73f78958a5/url HTTP/1.1" 200 72
2018-10-05 17:13:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63280/session/04c548dba08b734e0ee32f73f78958a5/url {"sessionId": "04c548dba08b734e0ee32f73f78958a5"}
2018-10-05 17:13:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63280 "GET /session/04c548dba08b734e0ee32f73f78958a5/url HTTP/1.1" 200 94
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63280/session/04c548dba08b734e0ee32f73f78958a5/source {"sessionId": "04c548dba08b734e0ee32f73f78958a5"}
2018-10-05 17:13:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63280 "GET /session/04c548dba08b734e0ee32f73f78958a5/source HTTP/1.1" 200 9364
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63280/session/04c548dba08b734e0ee32f73f78958a5/element {"using": "class name", "sessionId": "04c548dba08b734e0ee32f73f78958a5", "value": "ng-pristine ng-valid"}
2018-10-05 17:13:23 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63280 "POST /session/04c548dba08b734e0ee32f73f78958a5/element HTTP/1.1" 200 299
2018-10-05 17:13:23 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:13:23 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 53, in start_requests
    driver.find_element_by_class_name("ng-pristine ng-valid").send_keys(u"国家软件园")
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 564, in find_element_by_class_name
    return self.find_element(by=By.CLASS_NAME, value=name)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 978, in find_element
    'value': value})['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
InvalidSelectorException: Message: invalid selector: Compound class names not permitted
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 17:13:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:13:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:13:55 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:13:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:13:55 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:13:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:13:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:13:56 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:13:56 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:13:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:13:56 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:13:56 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63419/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:13:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63419
2018-10-05 17:14:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63419 "POST /session HTTP/1.1" 200 887
2018-10-05 17:14:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:14:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63419/session/b74a01573387295d9b1d00ae7e91698b/url {"url": "https://www.ele.me/home/", "sessionId": "b74a01573387295d9b1d00ae7e91698b"}
2018-10-05 17:14:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63419 "POST /session/b74a01573387295d9b1d00ae7e91698b/url HTTP/1.1" 200 72
2018-10-05 17:14:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:14:08 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63419/session/b74a01573387295d9b1d00ae7e91698b/url {"sessionId": "b74a01573387295d9b1d00ae7e91698b"}
2018-10-05 17:14:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63419 "GET /session/b74a01573387295d9b1d00ae7e91698b/url HTTP/1.1" 200 94
2018-10-05 17:14:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:14:08 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63419/session/b74a01573387295d9b1d00ae7e91698b/source {"sessionId": "b74a01573387295d9b1d00ae7e91698b"}
2018-10-05 17:14:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63419 "GET /session/b74a01573387295d9b1d00ae7e91698b/source HTTP/1.1" 200 9364
2018-10-05 17:14:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:14:08 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 51, in start_requests
    print etree.tostring(input_01)
  File "src\lxml\etree.pyx", line 3350, in lxml.etree.tostring
TypeError: Type 'list' cannot be serialized.
2018-10-05 17:14:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:14:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:14:44 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:14:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:14:44 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:14:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:14:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:14:45 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:14:45 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:14:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:14:45 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:14:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63545/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:14:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63545
2018-10-05 17:14:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63545 "POST /session HTTP/1.1" 200 887
2018-10-05 17:14:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:14:49 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63545/session/ada93a32a409e77494d1fb4efd5e6135/url {"url": "https://www.ele.me/home/", "sessionId": "ada93a32a409e77494d1fb4efd5e6135"}
2018-10-05 17:14:59 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63545 "POST /session/ada93a32a409e77494d1fb4efd5e6135/url HTTP/1.1" 200 72
2018-10-05 17:14:59 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63545/session/ada93a32a409e77494d1fb4efd5e6135/url {"sessionId": "ada93a32a409e77494d1fb4efd5e6135"}
2018-10-05 17:15:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63545 "GET /session/ada93a32a409e77494d1fb4efd5e6135/url HTTP/1.1" 200 94
2018-10-05 17:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63545/session/ada93a32a409e77494d1fb4efd5e6135/source {"sessionId": "ada93a32a409e77494d1fb4efd5e6135"}
2018-10-05 17:15:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63545 "GET /session/ada93a32a409e77494d1fb4efd5e6135/source HTTP/1.1" 200 9364
2018-10-05 17:15:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:15:02 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 52, in start_requests
    print etree.tostring(input_01)
  File "src\lxml\etree.pyx", line 3350, in lxml.etree.tostring
TypeError: Type 'list' cannot be serialized.
2018-10-05 17:15:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:16:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:16:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:16:39 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:16:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:16:39 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:16:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:16:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:16:40 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:16:40 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:16:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:16:40 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:16:40 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63771/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:16:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:63771
2018-10-05 17:16:44 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63771 "POST /session HTTP/1.1" 200 886
2018-10-05 17:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:16:44 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:63771/session/ce232fdbb2ba9974ce429998195e9352/url {"url": "https://www.ele.me/home/", "sessionId": "ce232fdbb2ba9974ce429998195e9352"}
2018-10-05 17:17:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63771 "POST /session/ce232fdbb2ba9974ce429998195e9352/url HTTP/1.1" 200 72
2018-10-05 17:17:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:17:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63771/session/ce232fdbb2ba9974ce429998195e9352/url {"sessionId": "ce232fdbb2ba9974ce429998195e9352"}
2018-10-05 17:17:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63771 "GET /session/ce232fdbb2ba9974ce429998195e9352/url HTTP/1.1" 200 94
2018-10-05 17:17:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:17:03 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:63771/session/ce232fdbb2ba9974ce429998195e9352/source {"sessionId": "ce232fdbb2ba9974ce429998195e9352"}
2018-10-05 17:17:03 [urllib3.connectionpool] DEBUG: http://127.0.0.1:63771 "GET /session/ce232fdbb2ba9974ce429998195e9352/source HTTP/1.1" 200 9364
2018-10-05 17:17:03 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:17:03 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 52, in start_requests
    print etree.tostring(input_01)
  File "src\lxml\etree.pyx", line 3350, in lxml.etree.tostring
TypeError: Type 'list' cannot be serialized.
2018-10-05 17:17:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:18:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:18:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:18:29 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:18:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:18:29 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:18:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:18:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:18:30 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:18:30 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:18:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:18:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:18:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64003/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:18:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64003
2018-10-05 17:18:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64003 "POST /session HTTP/1.1" 200 888
2018-10-05 17:18:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:18:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64003/session/eae34948a2fa112eff88d852f75dd597/url {"url": "https://www.ele.me/home/", "sessionId": "eae34948a2fa112eff88d852f75dd597"}
2018-10-05 17:18:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64003 "POST /session/eae34948a2fa112eff88d852f75dd597/url HTTP/1.1" 200 72
2018-10-05 17:18:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:18:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64003/session/eae34948a2fa112eff88d852f75dd597/url {"sessionId": "eae34948a2fa112eff88d852f75dd597"}
2018-10-05 17:18:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64003 "GET /session/eae34948a2fa112eff88d852f75dd597/url HTTP/1.1" 200 94
2018-10-05 17:18:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:18:49 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64003/session/eae34948a2fa112eff88d852f75dd597/source {"sessionId": "eae34948a2fa112eff88d852f75dd597"}
2018-10-05 17:18:49 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64003 "GET /session/eae34948a2fa112eff88d852f75dd597/source HTTP/1.1" 200 9364
2018-10-05 17:18:49 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:18:49 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 52, in start_requests
    print input_01.text
AttributeError: 'list' object has no attribute 'text'
2018-10-05 17:19:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:19:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:19:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:19:45 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:19:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:19:46 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:19:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:19:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:19:46 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:19:46 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:19:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:19:46 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:19:47 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64170/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:19:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64170
2018-10-05 17:19:51 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64170 "POST /session HTTP/1.1" 200 887
2018-10-05 17:19:51 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:19:51 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64170/session/463b25c33f543e0e0a05faf02fa65fa1/url {"url": "https://www.ele.me/home/", "sessionId": "463b25c33f543e0e0a05faf02fa65fa1"}
2018-10-05 17:20:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64170 "POST /session/463b25c33f543e0e0a05faf02fa65fa1/url HTTP/1.1" 200 72
2018-10-05 17:20:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:20:11 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64170/session/463b25c33f543e0e0a05faf02fa65fa1/url {"sessionId": "463b25c33f543e0e0a05faf02fa65fa1"}
2018-10-05 17:20:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64170 "GET /session/463b25c33f543e0e0a05faf02fa65fa1/url HTTP/1.1" 200 94
2018-10-05 17:20:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:20:11 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64170/session/463b25c33f543e0e0a05faf02fa65fa1/source {"sessionId": "463b25c33f543e0e0a05faf02fa65fa1"}
2018-10-05 17:20:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64170 "GET /session/463b25c33f543e0e0a05faf02fa65fa1/source HTTP/1.1" 200 9364
2018-10-05 17:20:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:20:11 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 52, in start_requests
    print input_01.text
AttributeError: 'list' object has no attribute 'text'
2018-10-05 17:20:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:20:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:20:49 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:20:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:20:49 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:20:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:20:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:20:50 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:20:50 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:20:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:20:50 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:20:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64321/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:20:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:64321
2018-10-05 17:20:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64321 "POST /session HTTP/1.1" 200 888
2018-10-05 17:20:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:20:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:64321/session/7b6ae189a289968063ea9a9f9d8d0cc8/url {"url": "https://www.ele.me/home/", "sessionId": "7b6ae189a289968063ea9a9f9d8d0cc8"}
2018-10-05 17:21:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64321 "POST /session/7b6ae189a289968063ea9a9f9d8d0cc8/url HTTP/1.1" 200 72
2018-10-05 17:21:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:21:07 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64321/session/7b6ae189a289968063ea9a9f9d8d0cc8/url {"sessionId": "7b6ae189a289968063ea9a9f9d8d0cc8"}
2018-10-05 17:21:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64321 "GET /session/7b6ae189a289968063ea9a9f9d8d0cc8/url HTTP/1.1" 200 94
2018-10-05 17:21:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:21:07 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:64321/session/7b6ae189a289968063ea9a9f9d8d0cc8/source {"sessionId": "7b6ae189a289968063ea9a9f9d8d0cc8"}
2018-10-05 17:21:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:64321 "GET /session/7b6ae189a289968063ea9a9f9d8d0cc8/source HTTP/1.1" 200 9364
2018-10-05 17:21:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:21:08 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 53, in start_requests
    print etree.tostring(input_01)
  File "src\lxml\etree.pyx", line 3350, in lxml.etree.tostring
TypeError: Type 'list' cannot be serialized.
2018-10-05 17:21:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:47:12 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:47:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:47:12 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:47:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:47:12 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:47:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:47:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:47:13 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:47:13 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:47:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:47:13 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:47:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:50462/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:47:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:50462
2018-10-05 17:47:17 [urllib3.connectionpool] DEBUG: http://127.0.0.1:50462 "POST /session HTTP/1.1" 200 887
2018-10-05 17:47:17 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:47:17 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:50462/session/f28c3fed171bbda3c14ac222efbdce84/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "f28c3fed171bbda3c14ac222efbdce84"}
2018-10-05 17:47:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:50462 "POST /session/f28c3fed171bbda3c14ac222efbdce84/url HTTP/1.1" 200 72
2018-10-05 17:47:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:47:22 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:50462/session/f28c3fed171bbda3c14ac222efbdce84/source {"sessionId": "f28c3fed171bbda3c14ac222efbdce84"}
2018-10-05 17:47:22 [urllib3.connectionpool] DEBUG: http://127.0.0.1:50462 "GET /session/f28c3fed171bbda3c14ac222efbdce84/source HTTP/1.1" 200 42376
2018-10-05 17:47:22 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:47:22 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 17:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> (referer: None)
2018-10-05 17:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 69, in parse
    content = response.body.text
AttributeError: 'str' object has no attribute 'text'
2018-10-05 17:47:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1968067> (referer: None)
2018-10-05 17:47:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1968067> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 69, in parse
    content = response.body.text
AttributeError: 'str' object has no attribute 'text'
2018-10-05 17:47:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=421477> (referer: None)
2018-10-05 17:47:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=421477> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 69, in parse
    content = response.body.text
AttributeError: 'str' object has no attribute 'text'
2018-10-05 17:47:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=164571362> (referer: None)
2018-10-05 17:47:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=164571362> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 69, in parse
    content = response.body.text
AttributeError: 'str' object has no attribute 'text'
2018-10-05 17:47:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166940885> (referer: None)
2018-10-05 17:47:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166940885> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 69, in parse
    content = response.body.text
AttributeError: 'str' object has no attribute 'text'
2018-10-05 17:54:57 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 17:54:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 17:54:57 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 17:54:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 17:54:57 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 17:54:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 17:54:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 17:54:58 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 17:54:58 [scrapy.core.engine] INFO: Spider opened
2018-10-05 17:54:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:54:58 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 17:54:59 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:51241/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 17:54:59 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:51241
2018-10-05 17:55:02 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51241 "POST /session HTTP/1.1" 200 887
2018-10-05 17:55:02 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:55:02 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:51241/session/ca7844de59d594b337e060140bff7fe3/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "ca7844de59d594b337e060140bff7fe3"}
2018-10-05 17:55:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51241 "POST /session/ca7844de59d594b337e060140bff7fe3/url HTTP/1.1" 200 72
2018-10-05 17:55:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:55:06 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:51241/session/ca7844de59d594b337e060140bff7fe3/source {"sessionId": "ca7844de59d594b337e060140bff7fe3"}
2018-10-05 17:55:06 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51241 "GET /session/ca7844de59d594b337e060140bff7fe3/source HTTP/1.1" 200 42199
2018-10-05 17:55:06 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 17:55:06 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 17:55:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 17:55:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1164082> (referer: None)
2018-10-05 17:55:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1164082> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 71, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 17:55:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=159328536> (referer: None)
2018-10-05 17:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=159328536> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 71, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 17:55:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=162079276> (referer: None)
2018-10-05 17:55:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=162079276> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 71, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 17:55:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1487399> (referer: None)
2018-10-05 17:55:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1487399> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 71, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 17:55:58 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:56:58 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 17:57:58 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:00:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:00:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:00:29 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:00:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:00:30 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:00:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:00:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:00:30 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:00:30 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:00:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:00:30 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:00:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:51856/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:00:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:51856
2018-10-05 18:00:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51856 "POST /session HTTP/1.1" 200 887
2018-10-05 18:00:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:00:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:51856/session/c875df4397f7730b324a0a00f9f54385/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "c875df4397f7730b324a0a00f9f54385"}
2018-10-05 18:00:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51856 "POST /session/c875df4397f7730b324a0a00f9f54385/url HTTP/1.1" 200 72
2018-10-05 18:00:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:00:54 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:51856/session/c875df4397f7730b324a0a00f9f54385/source {"sessionId": "c875df4397f7730b324a0a00f9f54385"}
2018-10-05 18:00:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:51856 "GET /session/c875df4397f7730b324a0a00f9f54385/source HTTP/1.1" 200 18180
2018-10-05 18:00:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:01:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:02:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:02:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:02:43 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:02:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:02:43 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:02:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:02:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:02:44 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:02:44 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:02:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:02:44 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:02:45 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52128/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:02:45 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52128
2018-10-05 18:02:48 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52128 "POST /session HTTP/1.1" 200 888
2018-10-05 18:02:48 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:02:48 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52128/session/0b9515d6fd82145aa755b19da315fbca/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "0b9515d6fd82145aa755b19da315fbca"}
2018-10-05 18:02:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52128 "POST /session/0b9515d6fd82145aa755b19da315fbca/url HTTP/1.1" 200 72
2018-10-05 18:02:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:02:50 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52128/session/0b9515d6fd82145aa755b19da315fbca/source {"sessionId": "0b9515d6fd82145aa755b19da315fbca"}
2018-10-05 18:02:50 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52128 "GET /session/0b9515d6fd82145aa755b19da315fbca/source HTTP/1.1" 200 42620
2018-10-05 18:02:50 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:02:50 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:02:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:02:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166976449> (referer: None)
2018-10-05 18:02:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166976449> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:02:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=165872132> (referer: None)
2018-10-05 18:02:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=165872132> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:03:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1524229> (referer: None)
2018-10-05 18:03:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1524229> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:03:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=157082558> (referer: None)
2018-10-05 18:03:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=157082558> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:03:44 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:04:44 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:11:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:11:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:11:05 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:11:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:11:05 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:11:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:11:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:11:06 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:11:06 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:11:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:11:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:11:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52917/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:11:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:52917
2018-10-05 18:11:09 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52917 "POST /session HTTP/1.1" 200 886
2018-10-05 18:11:09 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:11:09 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:52917/session/59a5c9e0cde8a1d0ffc2126584143713/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "59a5c9e0cde8a1d0ffc2126584143713"}
2018-10-05 18:11:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52917 "POST /session/59a5c9e0cde8a1d0ffc2126584143713/url HTTP/1.1" 200 72
2018-10-05 18:11:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:11:15 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:52917/session/59a5c9e0cde8a1d0ffc2126584143713/source {"sessionId": "59a5c9e0cde8a1d0ffc2126584143713"}
2018-10-05 18:11:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:52917 "GET /session/59a5c9e0cde8a1d0ffc2126584143713/source HTTP/1.1" 200 42597
2018-10-05 18:11:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:11:15 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:11:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:11:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166909342> (referer: None)
2018-10-05 18:11:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166909342> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 73, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:11:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=161345806> (referer: None)
2018-10-05 18:11:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=161345806> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 73, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:11:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=156993389> (referer: None)
2018-10-05 18:11:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=156993389> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 73, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:12:06 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:12:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:12:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:12:30 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:12:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:12:30 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:12:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:12:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:12:31 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:12:31 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:12:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:12:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:12:31 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53088/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:12:31 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53088
2018-10-05 18:12:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53088 "POST /session HTTP/1.1" 200 887
2018-10-05 18:12:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:12:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53088/session/f03879c0bc0eeb276e2237bd2b1d04c4/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "f03879c0bc0eeb276e2237bd2b1d04c4"}
2018-10-05 18:12:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53088 "POST /session/f03879c0bc0eeb276e2237bd2b1d04c4/url HTTP/1.1" 200 72
2018-10-05 18:12:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:12:43 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:53088/session/f03879c0bc0eeb276e2237bd2b1d04c4/source {"sessionId": "f03879c0bc0eeb276e2237bd2b1d04c4"}
2018-10-05 18:12:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53088 "GET /session/f03879c0bc0eeb276e2237bd2b1d04c4/source HTTP/1.1" 200 42704
2018-10-05 18:12:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:12:43 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1487399> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:13:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:13:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:13:10 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:13:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:13:11 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:13:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:13:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:13:11 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:13:11 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:13:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:13:11 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:13:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53199/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:13:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53199
2018-10-05 18:13:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53199 "POST /session HTTP/1.1" 200 886
2018-10-05 18:13:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:13:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53199/session/1bab3cfca4b47328764c14793bde750b/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "1bab3cfca4b47328764c14793bde750b"}
2018-10-05 18:13:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53199 "POST /session/1bab3cfca4b47328764c14793bde750b/url HTTP/1.1" 200 72
2018-10-05 18:13:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:13:18 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:53199/session/1bab3cfca4b47328764c14793bde750b/source {"sessionId": "1bab3cfca4b47328764c14793bde750b"}
2018-10-05 18:13:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53199 "GET /session/1bab3cfca4b47328764c14793bde750b/source HTTP/1.1" 200 42775
2018-10-05 18:13:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:13:18 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:13:18 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:13:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=155957932> (referer: None)
2018-10-05 18:13:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=155957932> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:13:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166961314> (referer: None)
2018-10-05 18:13:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166961314> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:13:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=158066226> (referer: None)
2018-10-05 18:13:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=158066226> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:14:11 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:15:11 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:16:11 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:17:11 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:18:11 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:18:31 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:18:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:18:31 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:18:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:18:31 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:18:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:18:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:18:32 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:18:32 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:18:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:18:32 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:18:32 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53713/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:18:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53713
2018-10-05 18:18:35 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53713 "POST /session HTTP/1.1" 200 887
2018-10-05 18:18:35 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:18:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53713/session/e30ec2ac76e85793e0a5bf71690c4cff/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "e30ec2ac76e85793e0a5bf71690c4cff"}
2018-10-05 18:18:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53713 "POST /session/e30ec2ac76e85793e0a5bf71690c4cff/url HTTP/1.1" 200 72
2018-10-05 18:18:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:18:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:53713/session/e30ec2ac76e85793e0a5bf71690c4cff/source {"sessionId": "e30ec2ac76e85793e0a5bf71690c4cff"}
2018-10-05 18:18:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53713 "GET /session/e30ec2ac76e85793e0a5bf71690c4cff/source HTTP/1.1" 200 42229
2018-10-05 18:18:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:18:38 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:18:39 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:18:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=167006329> (referer: None)
2018-10-05 18:18:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=167006329> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:18:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=444185> (referer: None)
2018-10-05 18:18:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=444185> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:20:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:20:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:20:34 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:20:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:20:34 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:20:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:20:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:20:35 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:20:35 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:20:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:20:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:20:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53930/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:20:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:53930
2018-10-05 18:20:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53930 "POST /session HTTP/1.1" 200 888
2018-10-05 18:20:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:20:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:53930/session/d1fcfd4f904fd93bd239d0b3d4598822/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "d1fcfd4f904fd93bd239d0b3d4598822"}
2018-10-05 18:20:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53930 "POST /session/d1fcfd4f904fd93bd239d0b3d4598822/url HTTP/1.1" 200 72
2018-10-05 18:20:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:20:42 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:53930/session/d1fcfd4f904fd93bd239d0b3d4598822/source {"sessionId": "d1fcfd4f904fd93bd239d0b3d4598822"}
2018-10-05 18:20:42 [urllib3.connectionpool] DEBUG: http://127.0.0.1:53930 "GET /session/d1fcfd4f904fd93bd239d0b3d4598822/source HTTP/1.1" 200 42346
2018-10-05 18:20:42 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:20:42 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=164571362> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:20:42 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=162979643> (referer: None)
2018-10-05 18:20:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=162979643> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = i.get('name')
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:21:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:22:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:23:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:24:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:25:35 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:26:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:26:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:26:20 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:26:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:26:20 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:26:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:26:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:26:21 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:26:21 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:26:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:26:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:26:21 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54502/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:26:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:54502
2018-10-05 18:26:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54502 "POST /session HTTP/1.1" 200 886
2018-10-05 18:26:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:26:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54502/session/04c512cec092332a241cd278806f1bde/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "04c512cec092332a241cd278806f1bde"}
2018-10-05 18:26:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54502 "POST /session/04c512cec092332a241cd278806f1bde/url HTTP/1.1" 200 72
2018-10-05 18:26:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:26:28 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54502/session/04c512cec092332a241cd278806f1bde/source {"sessionId": "04c512cec092332a241cd278806f1bde"}
2018-10-05 18:26:28 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54502 "GET /session/04c512cec092332a241cd278806f1bde/source HTTP/1.1" 200 42883
2018-10-05 18:26:28 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:26:28 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1487399> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:26:28 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:26:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=165999095> (referer: None)
2018-10-05 18:26:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=165999095> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 72, in parse
    item['name'] = json_obj['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:27:21 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:28:21 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:29:21 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:30:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:30:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:30:11 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:30:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:30:11 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:30:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:30:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:30:12 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:30:12 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:30:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:30:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:30:12 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54895/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:30:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:54895
2018-10-05 18:30:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54895 "POST /session HTTP/1.1" 200 887
2018-10-05 18:30:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:30:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:54895/session/f49ce21a50d741bedc9f76a46acfb167/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "f49ce21a50d741bedc9f76a46acfb167"}
2018-10-05 18:30:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54895 "POST /session/f49ce21a50d741bedc9f76a46acfb167/url HTTP/1.1" 200 72
2018-10-05 18:30:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:30:20 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:54895/session/f49ce21a50d741bedc9f76a46acfb167/source {"sessionId": "f49ce21a50d741bedc9f76a46acfb167"}
2018-10-05 18:30:20 [urllib3.connectionpool] DEBUG: http://127.0.0.1:54895 "GET /session/f49ce21a50d741bedc9f76a46acfb167/source HTTP/1.1" 200 42286
2018-10-05 18:30:20 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:30:20 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:31:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:32:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:32:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:32:19 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:32:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:32:19 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:32:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:32:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:32:20 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:32:20 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:32:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:32:20 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:32:20 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55124/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:32:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55124
2018-10-05 18:32:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55124 "POST /session HTTP/1.1" 200 888
2018-10-05 18:32:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:32:24 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55124/session/ad28e0fdfeaf5f55d770fccd33f2a384/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "ad28e0fdfeaf5f55d770fccd33f2a384"}
2018-10-05 18:32:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55124 "POST /session/ad28e0fdfeaf5f55d770fccd33f2a384/url HTTP/1.1" 200 72
2018-10-05 18:32:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:32:27 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:55124/session/ad28e0fdfeaf5f55d770fccd33f2a384/source {"sessionId": "ad28e0fdfeaf5f55d770fccd33f2a384"}
2018-10-05 18:32:27 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55124 "GET /session/ad28e0fdfeaf5f55d770fccd33f2a384/source HTTP/1.1" 200 42178
2018-10-05 18:32:27 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:32:27 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:33:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:34:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:34:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:34:05 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:34:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:34:05 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:34:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:34:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:34:06 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:34:06 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:34:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:34:06 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:34:06 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55331/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:34:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55331
2018-10-05 18:34:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55331 "POST /session HTTP/1.1" 200 887
2018-10-05 18:34:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:34:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55331/session/e96fccadd1fde346dab16b0b80a1d267/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "e96fccadd1fde346dab16b0b80a1d267"}
2018-10-05 18:34:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55331 "POST /session/e96fccadd1fde346dab16b0b80a1d267/url HTTP/1.1" 200 72
2018-10-05 18:34:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:34:12 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:55331/session/e96fccadd1fde346dab16b0b80a1d267/source {"sessionId": "e96fccadd1fde346dab16b0b80a1d267"}
2018-10-05 18:34:12 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55331 "GET /session/e96fccadd1fde346dab16b0b80a1d267/source HTTP/1.1" 200 42681
2018-10-05 18:34:12 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:34:12 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:34:12 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:34:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=234936> (referer: None)
2018-10-05 18:34:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=234936> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_obj['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:34:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=158563798> (referer: None)
2018-10-05 18:34:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=158563798> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_obj['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:35:06 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:36:06 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:38:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:38:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:38:35 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:38:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:38:35 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:38:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:38:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:38:36 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:38:36 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:38:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:38:36 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:38:36 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55783/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:38:36 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:55783
2018-10-05 18:38:41 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55783 "POST /session HTTP/1.1" 200 888
2018-10-05 18:38:41 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:38:41 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:55783/session/4468ed1ebb760aabceecbfe60881381b/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "4468ed1ebb760aabceecbfe60881381b"}
2018-10-05 18:42:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55783 "POST /session/4468ed1ebb760aabceecbfe60881381b/url HTTP/1.1" 200 72
2018-10-05 18:42:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:42:29 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:55783/session/4468ed1ebb760aabceecbfe60881381b/source {"sessionId": "4468ed1ebb760aabceecbfe60881381b"}
2018-10-05 18:42:29 [urllib3.connectionpool] DEBUG: http://127.0.0.1:55783 "GET /session/4468ed1ebb760aabceecbfe60881381b/source HTTP/1.1" 200 331
2018-10-05 18:42:29 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:42:29 [scrapy.core.engine] ERROR: Error while obtaining start requests
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\scrapy\core\engine.py", line 127, in _next_request
    request = next(slot.start_requests)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 57, in start_requests
    html = driver.page_source
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 679, in page_source
    return self.execute(Command.GET_PAGE_SOURCE)['value']
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 321, in execute
    self.error_handler.check_response(response)
  File "D:\python27\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=69.0.3497.100)
  (Driver info: chromedriver=2.42.591088 (7b2b2dca23cca0862f674758c9a3933e685c27d5),platform=Windows NT 10.0.17134 x86_64)

2018-10-05 18:42:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:42:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:42:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:42:38 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:42:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:42:38 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:42:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:42:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:42:39 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:42:39 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:42:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:42:39 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:42:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56214/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:42:39 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:56214
2018-10-05 18:42:43 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56214 "POST /session HTTP/1.1" 200 887
2018-10-05 18:42:43 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:42:43 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:56214/session/da35c164dfa7e709b56e44de267eff28/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "da35c164dfa7e709b56e44de267eff28"}
2018-10-05 18:43:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56214 "POST /session/da35c164dfa7e709b56e44de267eff28/url HTTP/1.1" 200 72
2018-10-05 18:43:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:43:40 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:56214/session/da35c164dfa7e709b56e44de267eff28/source {"sessionId": "da35c164dfa7e709b56e44de267eff28"}
2018-10-05 18:43:40 [urllib3.connectionpool] DEBUG: http://127.0.0.1:56214 "GET /session/da35c164dfa7e709b56e44de267eff28/source HTTP/1.1" 200 49733
2018-10-05 18:43:40 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:43:40 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:43:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:43:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1166239> (referer: None)
2018-10-05 18:43:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1166239> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:43:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1520281> (referer: None)
2018-10-05 18:43:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1520281> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:44:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:45:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:46:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:47:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:48:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:49:39 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:50:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:50:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:50:40 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:50:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:50:40 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:50:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:50:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:50:41 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:50:41 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:50:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:50:41 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:50:42 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57009/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:50:42 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57009
2018-10-05 18:50:46 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57009 "POST /session HTTP/1.1" 200 887
2018-10-05 18:50:46 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:50:46 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57009/session/f506184e8e247d3a6d84dac5fbeeb17a/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "f506184e8e247d3a6d84dac5fbeeb17a"}
2018-10-05 18:51:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57009 "POST /session/f506184e8e247d3a6d84dac5fbeeb17a/url HTTP/1.1" 200 72
2018-10-05 18:51:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:51:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:57009/session/f506184e8e247d3a6d84dac5fbeeb17a/source {"sessionId": "f506184e8e247d3a6d84dac5fbeeb17a"}
2018-10-05 18:51:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57009 "GET /session/f506184e8e247d3a6d84dac5fbeeb17a/source HTTP/1.1" 200 42737
2018-10-05 18:51:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:51:04 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 18:51:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 18:51:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=163031306> (referer: None)
2018-10-05 18:51:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=163031306> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:51:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1522516> (referer: None)
2018-10-05 18:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1522516> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:51:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166952384> (referer: None)
2018-10-05 18:51:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=166952384> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 18:51:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:51:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:51:34 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:51:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:51:34 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:51:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:51:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:51:35 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:51:35 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:51:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:51:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:51:35 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57143/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:51:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57143
2018-10-05 18:51:39 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57143 "POST /session HTTP/1.1" 200 886
2018-10-05 18:51:39 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:51:39 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57143/session/0826d4f79dddf1f2d796c2cc4ddf0390/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "0826d4f79dddf1f2d796c2cc4ddf0390"}
2018-10-05 18:53:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57143 "POST /session/0826d4f79dddf1f2d796c2cc4ddf0390/url HTTP/1.1" 200 72
2018-10-05 18:53:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:53:21 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:57143/session/0826d4f79dddf1f2d796c2cc4ddf0390/source {"sessionId": "0826d4f79dddf1f2d796c2cc4ddf0390"}
2018-10-05 18:53:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57143 "GET /session/0826d4f79dddf1f2d796c2cc4ddf0390/source HTTP/1.1" 200 4482
2018-10-05 18:53:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:53:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:53:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:54:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:54:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:54:13 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:54:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:54:13 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:54:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:54:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:54:14 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:54:14 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:54:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:54:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:54:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57433/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:54:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57433
2018-10-05 18:54:18 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57433 "POST /session HTTP/1.1" 200 887
2018-10-05 18:54:18 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:54:18 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57433/session/2b4da0040507bb2b804a7f48de5f36ce/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "2b4da0040507bb2b804a7f48de5f36ce"}
2018-10-05 18:58:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57433 "POST /session/2b4da0040507bb2b804a7f48de5f36ce/url HTTP/1.1" 200 72
2018-10-05 18:58:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:58:38 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:57433/session/2b4da0040507bb2b804a7f48de5f36ce/source {"sessionId": "2b4da0040507bb2b804a7f48de5f36ce"}
2018-10-05 18:58:38 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57433 "GET /session/2b4da0040507bb2b804a7f48de5f36ce/source HTTP/1.1" 200 4482
2018-10-05 18:58:38 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:58:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:58:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 18:58:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 18:58:53 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 18:58:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 18:58:54 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 18:58:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 18:58:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 18:58:54 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 18:58:54 [scrapy.core.engine] INFO: Spider opened
2018-10-05 18:58:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 18:58:54 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 18:58:55 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57900/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 18:58:55 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:57900
2018-10-05 18:59:00 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57900 "POST /session HTTP/1.1" 200 888
2018-10-05 18:59:00 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 18:59:00 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:57900/session/1eac4228611a02d9918873a9056ea741/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "1eac4228611a02d9918873a9056ea741"}
2018-10-05 19:00:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57900 "POST /session/1eac4228611a02d9918873a9056ea741/url HTTP/1.1" 200 72
2018-10-05 19:00:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 19:00:08 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:57900/session/1eac4228611a02d9918873a9056ea741/source {"sessionId": "1eac4228611a02d9918873a9056ea741"}
2018-10-05 19:00:08 [urllib3.connectionpool] DEBUG: http://127.0.0.1:57900 "GET /session/1eac4228611a02d9918873a9056ea741/source HTTP/1.1" 200 43047
2018-10-05 19:00:08 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 19:00:08 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 19:00:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:00:14 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 19:00:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=157476475> (referer: None)
2018-10-05 19:00:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=157476475> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 19:00:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1260046> (referer: None)
2018-10-05 19:00:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1260046> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 74, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 19:00:54 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:01:54 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:02:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-05 19:02:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-05 19:02:48 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'ROBOTSTXT_OBEY': True, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 3}
2018-10-05 19:02:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-05 19:02:48 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-05 19:02:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-05 19:02:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-05 19:02:49 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-05 19:02:49 [scrapy.core.engine] INFO: Spider opened
2018-10-05 19:02:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:02:49 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-05 19:02:50 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58317/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-05 19:02:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58317
2018-10-05 19:02:54 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58317 "POST /session HTTP/1.1" 200 888
2018-10-05 19:02:54 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 19:02:54 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58317/session/133fdd88f5c8928f917ff943cf255ea0/url {"url": "https://www.ele.me/place/wtts18zp5cgy?latitude=31.645957&longitude=120.310072", "sessionId": "133fdd88f5c8928f917ff943cf255ea0"}
2018-10-05 19:03:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58317 "POST /session/133fdd88f5c8928f917ff943cf255ea0/url HTTP/1.1" 200 72
2018-10-05 19:03:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 19:03:04 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:58317/session/133fdd88f5c8928f917ff943cf255ea0/source {"sessionId": "133fdd88f5c8928f917ff943cf255ea0"}
2018-10-05 19:03:04 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58317 "GET /session/133fdd88f5c8928f917ff943cf255ea0/source HTTP/1.1" 200 42717
2018-10-05 19:03:04 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-05 19:03:04 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=1021572> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2018-10-05 19:03:08 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.ele.me/robots.txt> (referer: None)
2018-10-05 19:03:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=164162904> (referer: None)
2018-10-05 19:03:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.ele.me/restapi/shopping/v2/menu?restaurant_id=164162904> (referer: None)
Traceback (most recent call last):
  File "D:\python27\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\python_workspace\Spider\hungrySpider\hungrySpider\spiders\hungry.py", line 75, in parse
    item['name'] = json_objs[i]['name']
TypeError: 'ItemMeta' object does not support item assignment
2018-10-05 19:03:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:04:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:05:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:06:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:07:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:08:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:09:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:10:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:11:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:12:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:13:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:14:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:15:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:16:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:17:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:18:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:19:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:20:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-05 19:21:49 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-06 16:28:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: hungrySpider)
2018-10-06 16:28:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 2.7.15 (v2.7.15:ca079a3ea3, Apr 30 2018, 16:22:17) [MSC v.1500 32 bit (Intel)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134
2018-10-06 16:28:59 [scrapy.crawler] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'hungrySpider.spiders', 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'SPIDER_LOADER_WARN_ONLY': True, 'SPIDER_MODULES': ['hungrySpider.spiders'], 'BOT_NAME': 'hungrySpider', 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'LOG_FILE': 'hungry.log', 'DOWNLOAD_DELAY': 2}
2018-10-06 16:28:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.corestats.CoreStats']
2018-10-06 16:28:59 [hungry] INFO: Reading start URLs from redis key 'hungrySpider:start_urls' (batch size: 16, encoding: utf-8
2018-10-06 16:29:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['hungrySpider.middlewares.CookiesMiddleware',
 'hungrySpider.middlewares.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'hungrySpider.middlewares.HungryspiderDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-10-06 16:29:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-10-06 16:29:00 [scrapy.middleware] INFO: Enabled item pipelines:
['hungrySpider.pipelines.HungryspiderPipeline',
 'scrapy_redis.pipelines.RedisPipeline']
2018-10-06 16:29:00 [scrapy.core.engine] INFO: Spider opened
2018-10-06 16:29:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-10-06 16:29:00 [hungry] INFO: Spider opened: hungry
2018-10-06 16:29:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-10-06 16:29:01 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session {"capabilities": {"alwaysMatch": {"goog:chromeOptions": {"args": [], "extensions": []}, "browserName": "chrome", "platformName": "any"}, "firstMatch": [{}]}, "desiredCapabilities": {"goog:chromeOptions": {"args": [], "extensions": []}, "platform": "ANY", "browserName": "chrome", "version": ""}}
2018-10-06 16:29:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:58276
2018-10-06 16:29:05 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session HTTP/1.1" 200 888
2018-10-06 16:29:05 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:05 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/url {"url": "https://www.ele.me/home/", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34"}
2018-10-06 16:29:07 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/url HTTP/1.1" 200 72
2018-10-06 16:29:07 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "xpath", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "//a[@class=\"mapcity-current ng-binding\"]"}
2018-10-06 16:29:10 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:10 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-1/click {"sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-1"}
2018-10-06 16:29:11 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-1/click HTTP/1.1" 200 72
2018-10-06 16:29:11 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "name", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "name"}
2018-10-06 16:29:13 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:13 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:13 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-2/value {"text": "\u65e0\u9521", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-2", "value": ["\u65e0", "\u9521"]}
2018-10-06 16:29:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-2/value HTTP/1.1" 200 72
2018-10-06 16:29:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "xpath", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "//ul[@class=\"mapcity-suggestlist ng-scope\"]/li[1]"}
2018-10-06 16:29:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:14 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-3/click {"sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-3"}
2018-10-06 16:29:14 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-3/click HTTP/1.1" 200 72
2018-10-06 16:29:14 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "xpath", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "//input[@class=\"ng-pristine ng-valid\"]"}
2018-10-06 16:29:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:15 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-4/value {"text": "\u56fd\u5bb6\u8f6f\u4ef6\u56ed", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-4", "value": ["\u56fd", "\u5bb6", "\u8f6f", "\u4ef6", "\u56ed"]}
2018-10-06 16:29:15 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-4/value HTTP/1.1" 200 72
2018-10-06 16:29:15 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "xpath", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "//button[@class=\"btn-stress\"]"}
2018-10-06 16:29:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-5/click {"sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-5"}
2018-10-06 16:29:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-5/click HTTP/1.1" 200 72
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element {"using": "xpath", "sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "value": "//ul[@class=\"ng-scope\"]/li[1]"}
2018-10-06 16:29:16 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element HTTP/1.1" 200 102
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:16 [selenium.webdriver.remote.remote_connection] DEBUG: POST http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-6/click {"sessionId": "f252ec1874bc98cccf4d8c5b60418a34", "id": "0.8862987082179759-6"}
2018-10-06 16:29:21 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "POST /session/f252ec1874bc98cccf4d8c5b60418a34/element/0.8862987082179759-6/click HTTP/1.1" 200 72
2018-10-06 16:29:21 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
2018-10-06 16:29:24 [selenium.webdriver.remote.remote_connection] DEBUG: GET http://127.0.0.1:58276/session/f252ec1874bc98cccf4d8c5b60418a34/url {"sessionId": "f252ec1874bc98cccf4d8c5b60418a34"}
2018-10-06 16:29:24 [urllib3.connectionpool] DEBUG: http://127.0.0.1:58276 "GET /session/f252ec1874bc98cccf4d8c5b60418a34/url HTTP/1.1" 200 145
2018-10-06 16:29:24 [selenium.webdriver.remote.remote_connection] DEBUG: Finished Request
